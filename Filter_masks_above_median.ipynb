{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "OXZ1W4ScDCs-",
        "FjEURG_eJLBm",
        "vStsBkwSJVrI",
        "zfhcOQOrJXmd"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marlenebauer/Deep_learning/blob/main/Filter_masks_above_median.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This script filters out those mask and raster tiles of training_tiles_above_median, that are already part of the testing set. As we do the splitting of training, validation and testing set before adding those tiles to the data augumentation, we need to make sure non of them are already in the testing set.\n",
        "This maintains the test set as a true representation of unseen data, allowing for an accurate evaluation of the modelâ€™s performance.\n"
      ],
      "metadata": {
        "id": "LaheC0go0s-b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set up"
      ],
      "metadata": {
        "id": "VB2BmJcE1pdL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#connect google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "tH3eZcHdC7T9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the following libraries\n",
        "import numpy as np\n",
        "import keras\n",
        "from keras import layers\n",
        "from tensorflow.keras import backend as K\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfdatasets\n",
        "import glob\n",
        "import random\n",
        "import os\n",
        "import shutil"
      ],
      "metadata": {
        "id": "UMK9_-dzeuDy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load tiles and generate training, validation and testing data"
      ],
      "metadata": {
        "id": "OXZ1W4ScDCs-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Set the path to the folder containing the mask and raster files\n",
        "raster_folder= '/content/drive/MyDrive/deep_learning_project/Training_tiles_filtered_zero/rasters_filtered_zero'\n",
        "mask_folder= '/content/drive/MyDrive/deep_learning_project/Training_tiles_filtered_zero/maks_filtered_zero'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMSm8bL9ctQK",
        "outputId": "a449081a-7a45-42de-8073-23baeb84c075"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8260\n",
            "8260\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get all files\n",
        "mask_files = sorted(glob.glob(mask_folder + '/*.npy'))\n",
        "print(f\"Total number of masks: {len(mask_files)}\")\n",
        "raster_files = sorted(glob.glob(raster_folder + '/*.npy'))\n",
        "print(f\"Total number of rasters: {len(raster_files)}\")"
      ],
      "metadata": {
        "id": "jl4rw5cjDahH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# stack the data\n",
        "data = np.column_stack((raster_paths, mask_paths))"
      ],
      "metadata": {
        "id": "0HWq180yXhnl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8MYQcsaOld-v",
        "outputId": "6eabdbe5-2f9c-4b1c-df81-ffd85a63b7d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8260"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data[0, ]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AInDt4bjc8dN",
        "outputId": "4d28abaa-4995-4703-f818-97600317a4c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['/content/drive/MyDrive/deep_learning_project/Training_tiles_filtered_zero/rasters_filtered_zero/32562_5513_raster_tile_0_1650.npy',\n",
              "       '/content/drive/MyDrive/deep_learning_project/Training_tiles_filtered_zero/maks_filtered_zero/32562_5513_mask_tile_0_1650.npy'],\n",
              "      dtype='<U132')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(5) # set seed to ensure reproducability\n",
        "np.random.shuffle(data)\n",
        "data[0,]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oKj-q5WCdHhx",
        "outputId": "91ce8dc6-09d8-4219-f104-3336ebe2d19f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['/content/drive/MyDrive/deep_learning_project/Training_tiles_filtered_zero/rasters_filtered_zero/32571_5516_raster_tile_2250_1100.npy',\n",
              "       '/content/drive/MyDrive/deep_learning_project/Training_tiles_filtered_zero/maks_filtered_zero/32571_5516_mask_tile_2250_1100.npy'],\n",
              "      dtype='<U132')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split in train, val and test\n",
        "prop_train = 0.70 # 70% for training\n",
        "prop_val = 0.15 #15% for validation -> 15% for testing\n",
        "\n",
        "# compute the split indices\n",
        "train_idx= int(prop_train * len(data))\n",
        "val_idx= int((prop_train+prop_val)*len(data))\n",
        "\n",
        "# Split the data\n",
        "training, validation, testing = np.split(data, [train_idx, val_idx])\n",
        "\n",
        "# Check training[0]\n",
        "training[0,]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fXZxOzlcdOSR",
        "outputId": "603fd1db-a158-45cb-a14c-587030af9555"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['/content/drive/MyDrive/deep_learning_project/Training_tiles_filtered_zero/rasters_filtered_zero/32571_5516_raster_tile_2250_1100.npy',\n",
              "       '/content/drive/MyDrive/deep_learning_project/Training_tiles_filtered_zero/maks_filtered_zero/32571_5516_mask_tile_2250_1100.npy'],\n",
              "      dtype='<U132')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(training))\n",
        "print(len(validation))\n",
        "print(len(testing))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z2Nn_4l0lhUf",
        "outputId": "259ab7b6-b1e5-4550-d2ab-3e88b546fc71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5782\n",
            "1239\n",
            "1239\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = tf.data.Dataset.from_tensor_slices((training[:,0], training[:,1]))"
      ],
      "metadata": {
        "collapsed": true,
        "id": "G0NITkSRdlz3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(train_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "L8H3-an2oLew",
        "outputId": "7002668e-4189-4964-b4f4-05c9a547cd0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensorflow.python.data.ops.from_tensor_slices_op._TensorSliceDataset"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>tensorflow.python.data.ops.from_tensor_slices_op._TensorSliceDataset</b><br/>def __init__(element, is_files=False, name=None)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/from_tensor_slices_op.py</a>A `Dataset` of slices from a dataset element.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 28);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NR1FWZpvlmqJ",
        "outputId": "48408db2-065d-44ee-9db0-0daeac427a91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5782"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to load .npy files\n",
        "def load_npy_files(raster_path, mask_path):\n",
        "    raster = np.load(raster_path.numpy().decode('utf-8'))\n",
        "    raster = np.transpose(raster, (1,2,0))\n",
        "\n",
        "    mask = np.load(mask_path.numpy().decode('utf-8'))\n",
        "    mask = np.expand_dims(mask, axis=-1)\n",
        "    return raster, mask\n",
        "\n",
        "# TensorFlow wrapper for loading .npy files\n",
        "def load_npy_tf(raster_path, mask_path):\n",
        "    raster, mask = tf.py_function(func=load_npy_files, inp=[raster_path, mask_path], Tout=[tf.float32, tf.float32])\n",
        "    raster.set_shape([128, 128, 3])  # Set shape for the raster image\n",
        "    mask.set_shape([128, 128, 1])\n",
        "    return raster, mask"
      ],
      "metadata": {
        "id": "6TktwASNeFBq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = train_ds.map(load_npy_tf)"
      ],
      "metadata": {
        "id": "ioNF-DcIfc8e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check the shape of our first element\n",
        "for element in train_ds.take(1):\n",
        "  print(element)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "oQKt1AhRowWM",
        "outputId": "f879e364-b532-45ad-eb86-50cd30fd589c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(<tf.Tensor: shape=(128, 128, 3), dtype=float32, numpy=\n",
            "array([[[ 83.,  89.,  69.],\n",
            "        [ 81.,  85.,  67.],\n",
            "        [ 80.,  85.,  67.],\n",
            "        ...,\n",
            "        [138., 126., 134.],\n",
            "        [139., 127., 136.],\n",
            "        [135., 125., 134.]],\n",
            "\n",
            "       [[ 83.,  89.,  70.],\n",
            "        [ 82.,  87.,  68.],\n",
            "        [ 79.,  84.,  66.],\n",
            "        ...,\n",
            "        [137., 126., 134.],\n",
            "        [137., 126., 135.],\n",
            "        [137., 126., 135.]],\n",
            "\n",
            "       [[ 75.,  82.,  65.],\n",
            "        [ 79.,  85.,  67.],\n",
            "        [ 79.,  86.,  67.],\n",
            "        ...,\n",
            "        [138., 126., 135.],\n",
            "        [137., 126., 135.],\n",
            "        [136., 125., 134.]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[123., 113., 126.],\n",
            "        [159., 145., 154.],\n",
            "        [171., 154., 158.],\n",
            "        ...,\n",
            "        [159., 145., 146.],\n",
            "        [179., 162., 157.],\n",
            "        [162., 143., 132.]],\n",
            "\n",
            "       [[ 79.,  81., 117.],\n",
            "        [101.,  95., 114.],\n",
            "        [149., 136., 145.],\n",
            "        ...,\n",
            "        [151., 138., 141.],\n",
            "        [168., 152., 151.],\n",
            "        [179., 161., 153.]],\n",
            "\n",
            "       [[ 87.,  97., 155.],\n",
            "        [ 68.,  67.,  95.],\n",
            "        [103.,  95., 108.],\n",
            "        ...,\n",
            "        [147., 134., 138.],\n",
            "        [154., 140., 142.],\n",
            "        [178., 162., 158.]]], dtype=float32)>, <tf.Tensor: shape=(128, 128, 1), dtype=float32, numpy=\n",
            "array([[[0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        ...,\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.]],\n",
            "\n",
            "       [[0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        ...,\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.]],\n",
            "\n",
            "       [[0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        ...,\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        ...,\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.]],\n",
            "\n",
            "       [[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.]],\n",
            "\n",
            "       [[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.]]], dtype=float32)>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-7s_Xv15lq6i",
        "outputId": "842419fb-87f2-4d7d-eb0d-b424866f58c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5782"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# now prepare val and test data\n",
        "val_ds = tf.data.Dataset.from_tensor_slices((validation[:,0], validation[:,1]))\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((testing[:,0], testing[:,1]))\n",
        "\n",
        "# load the arrays\n",
        "val_ds = val_ds.map(load_npy_tf)\n",
        "test_ds = test_ds.map(load_npy_tf)"
      ],
      "metadata": {
        "id": "29O7Q2SpgS1N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Filter out tiles, that are already in testing"
      ],
      "metadata": {
        "id": "FjEURG_eJLBm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# filter out those masks/rasters of Training_tiles_filtered_median, that are already included in testing\n",
        "# this is neccessary, because we first split the data into training, validation and testing and then add the masks/rasters above median\n",
        "# to our data augumentation.\n",
        "# Therefore, we have to make sure that the masks/rasters that we use for the Data augumentaion, are not included in the testing dataset\n",
        "# load in high prio tiles\n",
        "prio_mask_folder = '/content/drive/MyDrive/deep_learning_project/Training_tiles_filtered_median/masks_filtered_median'\n",
        "prio_raster_folder = '/content/drive/MyDrive/deep_learning_project/Training_tiles_filtered_median/rasters_filtered_median'\n",
        "\n",
        "prio_raster_paths = sorted(glob.glob(prio_raster_folder+'/*.npy'))\n",
        "prio_mask_paths = sorted(glob.glob(prio_mask_folder+'/*.npy'))\n",
        "\n",
        "print(len(prio_raster_paths))\n",
        "print(len(prio_mask_paths))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ovK3mB71v-ty",
        "outputId": "8ca1a52c-5206-4b5c-84fc-a0868c222b38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4129\n",
            "4129\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# stack the data\n",
        "#prio_data = np.column_stack((prio_raster_paths, prio_mask_paths))"
      ],
      "metadata": {
        "id": "BJT91kCKF8BF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#extract the filenames of the masks in the testing dataset\n",
        "testing_mask_filenames = [os.path.basename(pair[1]) for pair in testing]\n",
        "print(testing_mask_filenames)"
      ],
      "metadata": {
        "id": "XV6dnXSYwo0k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# only keep those masks, that are not already in the testing dataset\n",
        "filtered_prio_mask_paths = [path for path in prio_mask_paths if os.path.basename(path) not in testing_mask_filenames]\n"
      ],
      "metadata": {
        "id": "pkNa11nY0N2z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(filtered_prio_mask_paths))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-k6iYndzWBk",
        "outputId": "b441610c-520f-48be-e1db-0431be1e6c25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3502\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(prio_mask_paths))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EX4v_8y7zl4L",
        "outputId": "07108c3d-e427-4512-968d-daf14acd25ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4129\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## get the matching rasters"
      ],
      "metadata": {
        "id": "vStsBkwSJVrI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get the matching rasters for the filtered_prio_mask_paths\n",
        "def extract_common_part(filename):\n",
        "    basename = os.path.basename(filename)\n",
        "    parts = basename.split('_')\n",
        "    if len(parts) >= 6:\n",
        "        first_part = parts[0] + '_' + parts[1]  # \"32562_5513\"\n",
        "        tile_part = parts[-2] + '_' + parts[-1].replace('.npy', '')  # \"1000_1200\"\n",
        "        return first_part, tile_part\n",
        "    return None, None"
      ],
      "metadata": {
        "id": "vDrJ31TJ5OTA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#extract common parts\n",
        "raster_common_parts = set(extract_common_part(f) for f in prio_raster_paths)\n",
        "mask_common_parts = set(extract_common_part(f) for f in filtered_prio_mask_paths)"
      ],
      "metadata": {
        "id": "UiOmqC2N5UdD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#get masks\n",
        "matching_mask_files = [f for f in filtered_prio_mask_paths if extract_common_part(f) in raster_common_parts]\n",
        "print(f\"Number of matching masks: {len(matching_mask_files)}\")\n"
      ],
      "metadata": {
        "id": "W87NyEzA5eA7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#get rasters\n",
        "matching_raster_files = [f for f in prio_raster_paths\n",
        "                         if extract_common_part(f) in mask_common_parts]\n",
        "print(f\"Number of matching rasters: {len(matching_raster_files)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26r7qmE351eM",
        "outputId": "d41a0bf2-013c-4e28-a886-b25e0028ac7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of matching rasters: 3502\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Export filtered tiles"
      ],
      "metadata": {
        "id": "zfhcOQOrJXmd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # export matching rasters\n",
        "filtered_rasters_folder = '/content/drive/MyDrive/deep_learning_project/Training_tiles_filtered_median_new/rasters_filtered_median_testing'\n",
        "\n",
        "if not os.path.exists(filtered_rasters_folder):\n",
        "    os.makedirs(filtered_rasters_folder)\n",
        "\n",
        "# Copy matching raster files to the new folder\n",
        "for raster_file in matching_raster_files:\n",
        "    # Extract the filename from the full path\n",
        "    filename = os.path.basename(raster_file)\n",
        "\n",
        "    # Construct the destination path\n",
        "    destination_path = os.path.join(filtered_rasters_folder, filename)\n",
        "\n",
        "    # Copy the raster file to the 'filtered' folder\n",
        "    shutil.copy(raster_file, destination_path)\n",
        "\n",
        "print(f\"Copied {len(matching_raster_files)} raster files to the 'filtered_rasters' folder.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0WzlQurx51pC",
        "outputId": "189bf1bd-cf30-40b6-a49a-b46b16da8c00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copied 3502 raster files to the 'filtered_rasters' folder.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# export matching masks\n",
        "filtered_masks_folder = '/content/drive/MyDrive/deep_learning_project/Training_tiles_filtered_median_new/masks_filtered_median_testing'\n",
        "\n",
        "if not os.path.exists(filtered_masks_folder):\n",
        "    os.makedirs(filtered_masks_folder)\n",
        "\n",
        "# Copy matching raster files to the new folder\n",
        "for mask_file in matching_mask_files:\n",
        "    # Extract the filename from the full path\n",
        "    filename = os.path.basename(mask_file)\n",
        "\n",
        "    # Construct the destination path\n",
        "    destination_path = os.path.join(filtered_masks_folder, filename)\n",
        "\n",
        "    # Copy the raster file to the 'filtered' folder\n",
        "    shutil.copy(mask_file, destination_path)\n",
        "\n",
        "print(f\"Copied {len(matching_mask_files)} masks files to the 'filtered_masks' folder.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8siwVRP7vDU",
        "outputId": "7dd73fba-faaf-4c09-d33c-5bcd7ec3efaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copied 3502 masks files to the 'filtered_masks' folder.\n"
          ]
        }
      ]
    }
  ]
}